{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86875\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Decrease       0.69      0.50      0.58        58\n",
      "    Increase       0.90      0.95      0.92       262\n",
      "\n",
      "    accuracy                           0.87       320\n",
      "   macro avg       0.79      0.73      0.75       320\n",
      "weighted avg       0.86      0.87      0.86       320\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 29  29]\n",
      " [ 13 249]]\n",
      "Feature Importances:\n",
      "         Feature  Importance\n",
      "0   hour_of_day    0.278694\n",
      "6          temp    0.166795\n",
      "8      humidity    0.149760\n",
      "7           dew    0.085329\n",
      "12    windspeed    0.077089\n",
      "13   cloudcover    0.068939\n",
      "2         month    0.047427\n",
      "1   day_of_week    0.040369\n",
      "5    summertime    0.030912\n",
      "14   visibility    0.027654\n",
      "9        precip    0.011455\n",
      "4       weekday    0.010688\n",
      "3       holiday    0.003506\n",
      "11    snowdepth    0.001383\n",
      "10         snow    0.000000\n",
      "Best Parameters: {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': None}\n",
      "Best Cross-Validation Score: 0.8937596434710265\n",
      "Cross-Validation Mean Accuracy: 0.8953125\n",
      "Cross-Validation Std Dev: 0.008341467384399462\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Step 2: Load and Preprocess Dataset\n",
    "#training_file = \"D:/Data Science and Data Engineering/Semester 1/Period 2/Statistical Machine Learning/SML_Project/training_data_fall2024.csv\"\n",
    "training_file = \"training_data_fall2024.csv\"\n",
    "data = pd.read_csv(training_file)\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "data['increase_stock'] = label_encoder.fit_transform(data['increase_stock'])\n",
    "\n",
    "# Step 3: Split Data into Features and Target\n",
    "X = data.drop(columns=['increase_stock'])\n",
    "y = data['increase_stock']\n",
    "\n",
    "# Step 4: Split Dataset into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Step 5: Train Random Forest Model with Class Weights\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    class_weight='balanced',  \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate Model Predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Accuracy and Classification Report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, target_names=['Decrease', 'Increase'])\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Step 7: Feature Importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_classifier.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(\"Feature Importances:\\n\", feature_importances)\n",
    "\n",
    "# Step 8: Hyperparameter Tuning with RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=0),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=0\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", random_search.best_score_)\n",
    "\n",
    "# Step 9: Cross-Validation with New Features\n",
    "X['temp_dew_diff'] = X['temp'] - X['dew']  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "predefined_rf = RandomForestClassifier(\n",
    "    n_estimators=random_search.best_params_['n_estimators'],\n",
    "    max_depth=random_search.best_params_['max_depth'],\n",
    "    min_samples_split=random_search.best_params_['min_samples_split'],\n",
    "    min_samples_leaf=random_search.best_params_['min_samples_leaf'],\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "cv_scores = cross_val_score(predefined_rf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-Validation Mean Accuracy:\", np.mean(cv_scores))\n",
    "print(\"Cross-Validation Std Dev:\", np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial test_data shape: (400, 15)\n",
      "Initial test_data columns: Index(['hour_of_day', 'day_of_week', 'month', 'holiday', 'weekday',\n",
      "       'summertime', 'temp', 'dew', 'humidity', 'precip', 'snow', 'snowdepth',\n",
      "       'windspeed', 'cloudcover', 'visibility'],\n",
      "      dtype='object')\n",
      "Aligned test_data shape: (400, 16)\n",
      "Aligned test_data columns: Index(['hour_of_day', 'day_of_week', 'month', 'holiday', 'weekday',\n",
      "       'summertime', 'temp', 'dew', 'humidity', 'precip', 'snow', 'snowdepth',\n",
      "       'windspeed', 'cloudcover', 'visibility', 'temp_dew_diff'],\n",
      "      dtype='object')\n",
      "Generated predictions: [1 1 1 1 1 1 1 1 1 1]\n",
      "Number of mismatches: 1\n",
      "First 10 mismatches: [(0, Ellipsis, 1)]\n",
      "Predictions saved to 'predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Model Predictions\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load and preprocess test_data\n",
    "#test_file_path = \"D:/Data Science and Data Engineering/Semester 1/Period 2/Statistical Machine Learning/SML_Project/test_data_fall2024.csv\"\n",
    "test_file = \"test_data_fall2024.csv\"\n",
    "test_data = pd.read_csv(test_file)\n",
    "\n",
    "# Debug: Print the shape and columns of test_data\n",
    "print(\"Initial test_data shape:\", test_data.shape)\n",
    "print(\"Initial test_data columns:\", test_data.columns)\n",
    "\n",
    "# Add missing columns to test_data and align with X_train\n",
    "for col in X_train.columns:\n",
    "    if col not in test_data.columns:\n",
    "        test_data[col] = 0  \n",
    "\n",
    "# Align test_data columns with X_train\n",
    "test_data = test_data[X_train.columns]\n",
    "\n",
    "# Debug: Verify the alignment of test_data\n",
    "print(\"Aligned test_data shape:\", test_data.shape)\n",
    "print(\"Aligned test_data columns:\", test_data.columns)\n",
    "\n",
    "# Train the model if not already trained\n",
    "assert hasattr(predefined_rf, 'fit'), \"predefined_rf is not initialized!\"\n",
    "predefined_rf.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions using the aligned test_data\n",
    "final_predictions = predefined_rf.predict(test_data[:400])\n",
    "print(\"Generated predictions:\", final_predictions[:10])  \n",
    "\n",
    "# Compare predictions with the provided sequence\n",
    "provided_sequence = [...]  \n",
    "mismatches = [\n",
    "    (index, provided, predicted)\n",
    "    for index, (provided, predicted) in enumerate(zip(provided_sequence, final_predictions))\n",
    "    if provided != predicted\n",
    "]\n",
    "print(f\"Number of mismatches: {len(mismatches)}\")\n",
    "if len(mismatches) > 0:\n",
    "    print(\"First 10 mismatches:\", mismatches[:10])\n",
    "\n",
    "# Save predictions as a single row of comma-separated values\n",
    "output_path = \"predictions.csv\"\n",
    "#output_path = \"D:/Data Science and Data Engineering/Semester 1/Period 2/Statistical Machine Learning/SML_Project/predictions.csv\"\n",
    "with open(output_path, 'w') as f:\n",
    "    f.write(','.join(map(str, final_predictions)))\n",
    "print(f\"Predictions saved to '{output_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
